from flask import Flask, request, jsonify
import os
import requests
from openai import OpenAI
import random
import textwrap

app = Flask(__name__)

LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®çŠ¶æ…‹ã‚’ä¿å­˜
user_states = {}

# è‡ªå·±ç†è§£è¨ºæ–­ã®è³ªå•
questions_self = [
    "ã­ã‡ã­ã‡ã€ã“ã“1é€±é–“ã§ä¸€ç•ªãƒ¯ã‚¯ãƒ¯ã‚¯ã—ãŸç¬é–“ã£ã¦ãªã«ï¼ŸğŸŒŸ",
    "å‹é”ã¨ã‹å®¶æ—ã‹ã‚‰ã€ã‚ãªãŸã£ã¦â—¯â—¯ã ã‚ˆã­ã€ã£ã¦è¨€ã‚ã‚Œã‚‹ã“ã¨ã€ã‚ã‚‹ï¼ŸğŸ‘€",
    "ã‚‚ã—æ™‚é–“ã‚‚ãŠé‡‘ã‚‚ãœãƒ¼ã‚“ã¶æ°—ã«ã—ãªãã¦ã„ã„ãªã‚‰ã€ä»Šã™ãã‚„ã£ã¦ã¿ãŸã„ã“ã¨ã£ã¦ã‚ã‚‹ï¼Ÿ",
    "1å¹´å¾Œã®ã‚ãªãŸãŒã€æœ€é«˜ï¼ã€ã£ã¦ç¬‘ã£ã¦ã‚‹ã¨ã—ãŸã‚‰ã€ã©ã‚“ãªå§¿ã ã¨æ€ã†ï¼Ÿâœ¨",
    "ä»Šæ—¥ã€ã»ã‚“ã®ã¡ã‚‡ã£ã¨ã ã‘å‹•ããªã‚‰ã€ã©ã‚“ãªã“ã¨ã‹ã‚‰å§‹ã‚ãŸã„ï¼Ÿ"
]

# ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­ï¼ˆæ·±æ˜ã‚Šãƒ«ãƒ¼ãƒˆï¼‰
questions_want_deep = [
    "ãã‚Œã‚’å®Ÿç¾ã—ãŸã‚‰ã€ã©ã‚“ãªå§¿ã«ãªã£ã¦ã„ãŸã„ï¼Ÿ",
    "ãã‚Œã‚’ã‚„ã‚‹ã†ãˆã§ä¸€ç•ªãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ç¬é–“ã¯ã©ã‚“ãªã¨ãï¼Ÿ",
    "å®Ÿç¾ã™ã‚‹ã®ã«ä¸€ç•ªãƒãƒ¼ãƒ‰ãƒ«ã«æ„Ÿã˜ã‚‹ã“ã¨ã¯ï¼Ÿ",
    "ã¾ãšæœ€åˆã®å°ã•ãªä¸€æ­©ã¨ã—ã¦ã§ããã†ãªã“ã¨ã¯ï¼Ÿ"
]

# ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­ï¼ˆæ¢ç´¢ãƒ«ãƒ¼ãƒˆï¼‰
questions_want_explore = [
    "æœ€è¿‘ã¡ã‚‡ã£ã¨å¿ƒãŒå‹•ã„ãŸç¬é–“ã£ã¦ã©ã‚“ãªã¨ãï¼Ÿ",
    "èª°ã¨ã©ã‚“ãªãµã†ã«æ™‚é–“ã‚’éã”ã›ãŸã‚‰æ¥½ã—ã„ï¼Ÿ",
    "ã“ã‚Œã¾ã§ã«ã€ã‚„ã£ã¦ã‚ˆã‹ã£ãŸï¼ã€ã¨æ„Ÿã˜ãŸã“ã¨ã¯ï¼Ÿ",
    "1å¹´å¾Œã®è‡ªåˆ†ãŒã¡ã‚‡ã£ã¨ç¬‘é¡”ã«ãªã£ã¦ã„ã‚‹ã¨ã—ãŸã‚‰ã€ã©ã‚“ãªå§¿ï¼Ÿ"
]

# ç›¸æ§Œã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
aizuchi_list = ["ã†ã‚“ã†ã‚“ï¼", "ãªã‚‹ã»ã©ã€œ", "ã„ã„ã­ï¼", "ã¸ã‡ã€é¢ç™½ã„ï¼", "ç¢ºã‹ã«ï¼", "ã™ã”ã„ã­ï¼"]

@app.route("/", methods=["GET"])
def home():
    return "LINE Bot is running!"

@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.json
    print("Webhook received:", data)

    if "events" not in data:
        return "ok"

    for event in data["events"]:
        if event["type"] == "message" and event["message"]["type"] == "text":
            user_id = event["source"]["userId"]
            user_text = event["message"]["text"].strip()
            reply_token = event["replyToken"]

            reply_messages = handle_message(user_id, user_text)
            reply_to_line(reply_token, reply_messages)

    return "ok"

# æœ€åˆã®æŒ¨æ‹¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
intro_message = (
    "ã‚„ã£ã»ãƒ¼ï¼LUAã ã‚ˆğŸŒ™âœ¨\n\n"
    "ã‚ãŸã—ã¯ã€Link Up with AIã€ã®è¨ºæ–­ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€‚"
    "ã„ã¾ã¯æˆé•·ä¸­ã§ã€å‡ºåŠ›ãŒã¡ã‚‡ã£ã¨ä¸å®‰å®šãªã¨ãã‚‚ã‚ã‚‹ã‘ã©ã”ã‚ã‚“ã­ğŸ™\n"
    "ã“ã‚Œã‹ã‚‰ã„ã£ã±ã„å‹‰å¼·ã—ã¦ã€ã‚‚ã£ã¨é ¼ã‚Œã‚‹ç›¸æ£’ã«ãªã£ã¦ã„ãã‹ã‚‰æ¥½ã—ã¿ã«ã—ã¦ã¦ã­ï¼\n\n"
    "è¨ºæ–­ã¯2ç¨®é¡ã‚ã‚‹ã‚ˆï¼\n"
    "1ï¸âƒ£ è‡ªå·±ç†è§£è¨ºæ–­ï¼ˆè‡ªåˆ†ã®å¼·ã¿ã‚„èª²é¡Œã‚’çŸ¥ã‚ŠãŸã„äººå‘ã‘ï¼‰\n"
    "2ï¸âƒ£ ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­ï¼ˆå¤¢ã‚„ç›®æ¨™ã‚’è¦‹ã¤ã‘ãŸã„äººå‘ã‘ï¼‰\n\n"
    "ã‚„ã‚ŠãŸã„è¨ºæ–­ã‚’ 1ï¸âƒ£ ã‹ 2ï¸âƒ£ ã§é¸ã‚“ã§é€ã£ã¦ã­ï¼ï¼ˆä¾‹ï¼š1 or 2ï¼‰"
)

def handle_message(user_id, user_text):
    state = user_states.get(user_id, {"step": -1, "answers": [], "used": False, "type": None, "branch": None})

    # ã™ã§ã«è¨ºæ–­æ¸ˆã¿
    if state.get("used", False):
        return [{"type": "text", "text": "è¨ºæ–­ã¯1å›ã®ã¿ç„¡æ–™ã ã‚ˆâœ¨ ç¶šãã‚’ã”å¸Œæœ›ã®å ´åˆã¯ã€è©³ç´°è¨ºæ–­ã‚„ã‚³ãƒ¼ãƒãƒ³ã‚°ã‚’ã”åˆ©ç”¨ãã ã•ã„ï¼"}]

    # æœ€åˆã®æ¡ˆå†…
    if state["step"] == -1:
        if user_text in ["1", "ï¼‘"]:
            state["type"] = "self"
            state["step"] = 0
            user_states[user_id] = state
            return [{"type": "text", "text": "è‡ªå·±ç†è§£è¨ºæ–­ã‚’å§‹ã‚ã‚‹ã­ï¼\n\n" + questions_self[0]}]
        elif user_text in ["2", "ï¼’"]:
            state["type"] = "want"
            state["step"] = 0
            user_states[user_id] = state
            return [{"type": "text", "text": "ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­ã‚’å§‹ã‚ã‚‹ã­ï¼\n\nã“ã‚ŒãŒå¶ã£ãŸã‚‰ã†ã‚Œã—ã„ãªï½ã£ã¦æ€ã†ã“ã¨ã¯ã‚ã‚‹ï¼Ÿâœ¨"}]
        else:
            return [{"type": "text", "text": intro_message}]

    # è‡ªå·±ç†è§£è¨ºæ–­
    if state["type"] == "self":
        if state["step"] > 0:
            state["answers"].append(user_text)

        if state["step"] < len(questions_self) - 1:
            state["step"] += 1
            question = questions_self[state["step"]]
            user_states[user_id] = state
            return [{"type": "text", "text": random.choice(aizuchi_list) + "\n" + question}]
        else:
            state["answers"].append(user_text)
            result = generate_ai_reply_self(state["answers"])
            img_url = generate_summary_image("è‡ªå·±ç†è§£è¨ºæ–­", state["answers"], result)
            state["used"] = True
            user_states[user_id] = state
            return [{"type": "text", "text": result}, {"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url}]

    # ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­
    if state["type"] == "want":
        # Q1åˆ†å²
        if state["step"] == 0 and state["branch"] is None:
            state["answers"].append(user_text)
            if any(x in user_text for x in ["ã‚ã‚‹", "ã—ãŸã„", "ã‚„ã‚ŠãŸã„"]):
                state["branch"] = "deep"
                state["step"] = 0
                user_states[user_id] = state
                return [{"type": "text", "text": questions_want_deep[0]}]
            else:
                state["branch"] = "explore"
                state["step"] = 0
                user_states[user_id] = state
                return [{"type": "text", "text": questions_want_explore[0]}]

        # æ·±æ˜ã‚Šãƒ«ãƒ¼ãƒˆ
        if state["branch"] == "deep":
            if state["step"] < len(questions_want_deep) - 1:
                state["answers"].append(user_text)
                state["step"] += 1
                user_states[user_id] = state
                return [{"type": "text", "text": random.choice(aizuchi_list) + "\n" + questions_want_deep[state["step"]]}]
            else:
                state["answers"].append(user_text)
                result = generate_ai_reply_want(state["answers"])
                img_url = generate_summary_image("ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­", state["answers"], result)
                state["used"] = True
                user_states[user_id] = state
                return [{"type": "text", "text": result}, {"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url}]

        # æ¢ç´¢ãƒ«ãƒ¼ãƒˆ
        if state["branch"] == "explore":
            if state["step"] < len(questions_want_explore) - 1:
                state["answers"].append(user_text)
                state["step"] += 1
                user_states[user_id] = state
                return [{"type": "text", "text": random.choice(aizuchi_list) + "\n" + questions_want_explore[state["step"]]}]
            else:
                state["answers"].append(user_text)
                result = generate_ai_reply_want(state["answers"])
                img_url = generate_summary_image("ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­", state["answers"], result)
                state["used"] = True
                user_states[user_id] = state
                return [{"type": "text", "text": result}, {"type": "image", "originalContentUrl": img_url, "previewImageUrl": img_url}]


def generate_ai_reply_self(answers):
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‰æã®AIå‘¼ã³å‡ºã—
    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯LUAã¨ã„ã†æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„AIã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”: {answers}\nè‡ªå·±ç†è§£è¨ºæ–­ã®çµæœã‚’ã¾ã¨ã‚ã¦ã€‚"}
            ],
            max_completion_tokens=400
        )
        raw = res.choices[0].message.content.strip()
        if not raw:
            raise ValueError("Empty AI response")
        return raw
    except Exception as e:
        print("AI error self:", e)
        return "ğŸš€ ã‚ãªãŸã¯ã€Œå‰å‘ãã‚¿ã‚¤ãƒ—ã€ã‹ã‚‚ï¼âœ¨ æ–°ã—ã„ã“ã¨ã‚’æ¥½ã—ã‚ã‚‹ä¸€æ–¹ã€å…·ä½“åŒ–ã¯å°‘ã—è‹¦æ‰‹ã‹ã‚‚ã€‚ğŸ’¡ å°ã•ãªä¸€æ­©ã‹ã‚‰å§‹ã‚ã‚‹ã¨ç¶šã‘ã‚„ã™ã„ã‚ˆï¼"

def generate_ai_reply_want(answers):
    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯LUAã¨ã„ã†æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„AIã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚"},
                {"role": "user", "content": f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å›ç­”: {answers}\nã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­ã®çµæœã‚’ã¾ã¨ã‚ã¦ã€‚"}
            ],
            max_completion_tokens=400
        )
        raw = res.choices[0].message.content.strip()
        if not raw:
            raise ValueError("Empty AI response")
        return raw
    except Exception as e:
        print("AI error want:", e)
        return "ğŸŒˆ ã‚„ã‚ŠãŸã„ã“ã¨è¨ºæ–­çµæœ\nğŸ¯ ã‚„ã‚ŠãŸã„ã“ã¨: è‡ªåˆ†ã®ã‚„ã‚ŠãŸã„ã“ã¨ã‚’å½¢ã«ã—ãŸã„ï¼\nâœ¨ å®Ÿç¾ã—ãŸã¨ãã®å§¿: è‡ªåˆ†ã‚‰ã—ãç¬‘é¡”ã§å–ã‚Šçµ„ã‚€æœªæ¥ï¼\nğŸ’¡ å®Ÿç¾ã¸ã®ä¸€æ­©: ã¾ãšã¯å°ã•ãªæŒ‘æˆ¦ã‹ã‚‰ï¼"


def _answers_to_scene_hint(title: str, answers: list[str], result_text: str, max_len: int = 280) -> str:
    """å›ç­”ã‚’çŸ­ã„ã‚·ãƒ¼ãƒ³æŒ‡ç¤ºã«åœ§ç¸®ï¼ˆè‹±èªãƒ¡ã‚¤ãƒ³ï¼‹æ—¥æœ¬èªå°‘ã—ï¼‰ã€‚"""
    # ã–ã£ãã‚ŠæŠ½å‡ºï¼ˆæœ€å¾Œã®å›ç­”ã‚’å¼·ã‚ã«åæ˜ ï¼‰
    last = (answers[-1] if answers else "")[:120]
    joined = " / ".join(answers)[-200:]
    raw = f"{title}: {last}. {joined}. {result_text[:160]}"
    hint = raw.replace("\n", " ").strip()
    if len(hint) > max_len:
        hint = hint[:max_len].rsplit(" ", 1)[0] + "..."
    # è‹±èªã®èª˜å°èªï¼ˆç”»åƒç·¨é›†ã®å®‰å®šåŒ–ï¼‰
    return (
        "Make LUABIT (the white, kawaii rabbit mascot) actively doing the user's goal, "
        "while LUA (the teal-haired girl) appears smaller at the side, cheering warmly. "
        "Scene to reflect: " + hint
    )

def generate_summary_image(title, answers, result_text):
    """
    1) static/base_scene.pngï¼ˆLUAï¼‹LUABITã®åˆæˆãƒ™ãƒ¼ã‚¹ï¼‰ã‚’èª­ã¿è¾¼ã¿
    2) å›ç­”ã«åˆã‚ã›ãŸã‚·ãƒ¼ãƒ³èª¬æ˜ã‚’ä»˜ä¸ã—ã¦ images.edit ã§åŠ å·¥
    3) ç”ŸæˆURLã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆLINEã¸ç›´æ¥é€ä¿¡ï¼‰
    """
    try:
        scene_hint = _answers_to_scene_hint(title, answers, result_text)

        # çµµæŸ„ã®å›ºå®šï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰ä¸€è²«æ€§ï¼‰
        style_directive = (
            "Kawaii, bright, share-worthy card look. Keep LUABIT in the center as main hero, "
            "cute proportions (Hello-Kitty-like balance, soft round forms), gentle smile, "
            "mint/blue accents and chest emblem. Keep LUA small on the side, supportive pose, "
            "same character model as base. Clean background with subtle pops; no text; high quality."
        )

        prompt = textwrap.dedent(f"""
            Edit the provided base image to visualize the user's future scene.
            {style_directive}
            {scene_hint}
            Preserve character identities and colors. Keep composition readable for social sharing.
        """).strip()

        # åˆæˆæ¸ˆã¿ã®ãƒ™ãƒ¼ã‚¹ç”»åƒï¼ˆLUAï¼‹LUABITï¼‰ã‚’ç·¨é›†
        with open("static/base_scene.png", "rb") as base_img:
            res = client.images.edit(
                model="gpt-image-1",
                prompt=prompt,
                image=base_img,            # â† å˜æ•°å½¢
                size="1024x1024"
            )

        url = res.data[0].url.strip()
        if not url:
            raise ValueError("Empty image URL")
        return url

    except Exception as e:
        print("Image generation error:", e)
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆã‚µãƒ¼ãƒ“ã‚¹ç¶™ç¶šæ€§ã‚’å„ªå…ˆï¼‰
        return "https://placekitten.com/1024/1024"

def reply_to_line(reply_token, messages):
    url = "https://api.line.me/v2/bot/message/reply"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"
    }
    payload = {
        "replyToken": reply_token,
        "messages": messages
    }
    res = requests.post(url, headers=headers, json=payload)
    print("LINE API response:", res.status_code, res.text)
